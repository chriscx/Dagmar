// Generated by CoffeeScript 1.9.3
(function() {
  var Crawler, EventEmitter, Queue, http, request, sleep, util;

  EventEmitter = require('events').EventEmitter;

  util = require('util');

  request = require('request');

  Queue = require('./queue');

  sleep = require('sleep');

  http = require('http');

  Crawler = (function() {
    function Crawler(rateLimit, maxRequests) {
      if (rateLimit == null) {
        rateLimit = 10;
      }
      if (maxRequests == null) {
        maxRequests = 10;
      }
      this._rateLimit = rateLimit;
      this._maxRequests = maxRequests;
      this._nbRequests = 0;
      this._queue = new Queue();
      this._event = new EventEmitter();
      this._forEachCallback = function(error, response, body) {
        if (!error && response.statusCode === 200) {
          return console.log(body);
        } else {
          return console.log(error);
        }
      };
      this._endCallback = function() {
        return console.log('end.');
      };
    }

    Crawler.prototype.forEach = function(callback) {

      /*
      Callback to be executed when url has been requested
       */
      this._forEachCallback = callback;
      return this;
    };

    Crawler.prototype.end = function(callback) {

      /*
      Callback to be executed when queue is empty
       */
      this._endCallback = callback;
      return this;
    };

    Crawler.prototype.queue = function(url) {

      /*
      Push an url in the queue to be crawled
       */
      this._queue.push(url);
      return this;
    };

    Crawler.prototype.crawl = function(url) {

      /*
      Request url and manage results in callback specified by do function
       */
      return request(url, this._forEachCallback);
    };

    Crawler.prototype.start = function() {

      /*
      Will start crawling all urls in the queue
       */
      var event, req;
      event = new EventEmitter();
      req = function(url, callback) {
        var response;
        console.log("Fake http request to " + url);
        response = {
          statusCode: 200
        };
        return setTimeout(function() {
          return callback(null, response, 'fake body');
        }, 1000);
      };
      event.on('crawl_next', function(self) {
        var url;
        url = self._queue.pop();
        if (url != null) {
          console.log(url);
          sleep.usleep(self._rateLimit);
          request(url, function(error, response, body) {
            self._nbRequests--;
            sleep.usleep(self._rateLimit);
            self._forEachCallback(error, response, body);
            if (self._queue.size > 0) {
              return process.nextTick(function() {
                return event.emit('crawl_next', self);
              });
            } else {
              return event.emit('crawl_end');
            }
          });
          return self._nbRequests++;
        }
      });
      event.once('crawl_end', this._endCallback);
      while (this._nbRequests < this._maxRequests && this._queue.size > 0) {
        event.emit('crawl_next', this);
      }
      return this;
    };

    return Crawler;

  })();

  module.exports = Crawler;

}).call(this);
